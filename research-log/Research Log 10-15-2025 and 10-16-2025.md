### The Focus for these Two Days

Exploring neural network architectures that maintain performance under translational and rotational transformations of gravitational lensing data. Investigating the mathematical foundations of group theory and its application to equivariant and invariant neural networks for astrophysical data analysis.
***
### What I was able to accomplish

- Successfully set up and launched 10 parallel batch jobs on Amarel for mock lens generation
    
- Studied fundamental concepts of group theory and symmetry operations
    
- Learned about the mathematical distinctions between equivariance,
```math
f(t(x)) = t'(f(x)),
```
  and invariance,
```math
f(t(x)) = f(x).
```

- Explored how these concepts apply to gravitational lensing systems where image positions may be rotated or translated
    
- Continued investigating sequential neural network implementations in Keras and researched more about how the neural network is saved using `model.save()` and `model.load()`. 
	- I found that this saves the model architecture as well as the weights and biases if the model had been trained prior to saving.
	- What I found interesting here is the models can also be saved architecturally (by saving it as a json) and that the weights can be saved separated as well!

***
### Results

***
### Challenges & Pause Points

***
### Questions & Ideas

***
### Next Steps

##### Tags:




